#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HIPAA Penetration Testing Suite

This script performs comprehensive HIPAA security penetration testing on the Novamind 
concierge psychiatry platform API. It simulates various attacks to identify potential 
vulnerabilities related to Protected Health Information (PHI) exposure, authentication 
bypass, authorization flaws, and other HIPAA-relevant security concerns.

Usage:
    ./hipaa_pentest.py [target_url] [--verbose] [--output-dir DIR]

Requirements:
    Python 3.8+
    Required packages: requests, rich, cryptography, beautifulsoup4
"""

import argparse
import json
import os
import sys
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any

try:
    import requests
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
    from rich.table import Table
    from requests.exceptions import RequestException
    from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
    from cryptography.hazmat.primitives import padding
    from cryptography.hazmat.backends import default_backend
except ImportError:
    print("Required dependencies not found. Please install the required packages:")
    print("pip install -r requirements-security.txt")
    sys.exit(1)

# Initialize Rich console for pretty output
console = Console()

# HIPAA-specific security tests
class HIPAAPentestSuite:
    """HIPAA-focused penetration testing suite for healthcare APIs"""
    
    def __init__(self, target_url: str, output_dir: str = "security-reports", verbose: bool = False):
        """
        Initialize the HIPAA pentest suite
        
        Args:
            target_url: Base URL of the API to test
            output_dir: Directory to save test results
            verbose: Enable verbose output
        """
        self.target_url = target_url.rstrip('/')
        self.output_dir = output_dir
        self.verbose = verbose
        self.vulnerabilities = []
        self.session = requests.Session()
        
        # Prepare output directory
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # Test metadata
        self.test_id = str(uuid.uuid4())
        self.test_timestamp = datetime.now().isoformat()
        
        # Mock test credentials - in a real environment, these would be test accounts
        self.test_users = {
            "admin": {"username": "test_admin", "password": "Test@dmin123!"},
            "doctor": {"username": "test_doctor", "password": "Test@doctor123!"},
            "patient": {"username": "test_patient", "password": "Test@patient123!"},
            "invalid": {"username": "invalid_user", "password": "invalid_password"}
        }
        
        if verbose:
            console.print(f"[bold green]HIPAA Penetration Test Suite[/bold green]")
            console.print(f"Target: {target_url}")
            console.print(f"Test ID: {self.test_id}")
            console.print(f"Timestamp: {self.test_timestamp}")
            console.print()

    def run_all_tests(self) -> Dict:
        """Run all HIPAA security tests and return results"""
        with Progress(
            SpinnerColumn(),
            TextColumn("[bold blue]{task.description}[/bold blue]"),
            BarColumn(),
            TextColumn("[bold]{task.completed}/{task.total}[/bold]"),
            console=console,
        ) as progress:
            task = progress.add_task("[bold]Running HIPAA Security Tests...", total=7)
            
            # Authentication Tests
            self._test_authentication_bypass()
            progress.update(task, advance=1)
            
            # Authorization Tests
            self._test_unauthorized_phi_access()
            progress.update(task, advance=1)
            
            # PHI Protection Tests
            self._test_unencrypted_phi_transmission()
            progress.update(task, advance=1)
            
            # Audit Trail Tests
            self._test_audit_logging()
            progress.update(task, advance=1)
            
            # Error Handling Tests
            self._test_error_information_disclosure()
            progress.update(task, advance=1)
            
            # Rate Limiting Tests
            self._test_brute_force_protection()
            progress.update(task, advance=1)
            
            # Session Management Tests
            self._test_session_management()
            progress.update(task, advance=1)
        
        # Prepare and return results
        results = self._prepare_results()
        self._save_results(results)
        self._display_summary(results)
        return results

    def _test_authentication_bypass(self) -> None:
        """Test for authentication bypass vulnerabilities"""
        if self.verbose:
            console.print("[bold]Testing Authentication Bypass Vulnerabilities[/bold]")
        
        # Test 1: Basic auth bypass attempts
        protected_endpoints = [
            "/api/patients",
            "/api/appointments",
            "/api/medical-records",
            "/api/billing"
        ]
        
        for endpoint in protected_endpoints:
            url = f"{self.target_url}{endpoint}"
            try:
                # Attempt to access without authentication
                response = self.session.get(url, timeout=10)
                
                # Check if access was incorrectly granted
                if response.status_code < 400:
                    self.vulnerabilities.append({
                        "type": "Authentication Bypass",
                        "endpoint": endpoint,
                        "severity": "Critical",
                        "description": f"Endpoint {endpoint} accessible without authentication",
                        "remediation": "Implement proper authentication middleware for all PHI-related endpoints"
                    })
            except RequestException as e:
                if self.verbose:
                    console.print(f"[yellow]Error testing {endpoint}: {str(e)}[/yellow]")
        
        # Test 2: JWT token tampering
        # Simplified simulation of JWT token tampering
        self._simulate_jwt_attack()

    def _test_unauthorized_phi_access(self) -> None:
        """Test for unauthorized PHI access vulnerabilities"""
        if self.verbose:
            console.print("[bold]Testing Unauthorized PHI Access[/bold]")
        
        # Authenticate as patient user
        patient_token = self._simulate_login(self.test_users["patient"])
        
        # Attempt to access another patient's data
        if patient_token:
            try:
                other_patient_id = "PT12345"  # Simulated other patient ID
                url = f"{self.target_url}/api/patients/{other_patient_id}/medical-records"
                
                headers = {"Authorization": f"Bearer {patient_token}"}
                response = self.session.get(url, headers=headers, timeout=10)
                
                # Check if access was incorrectly granted to another patient's PHI
                if response.status_code < 400:
                    self.vulnerabilities.append({
                        "type": "Unauthorized PHI Access",
                        "endpoint": f"/api/patients/{other_patient_id}/medical-records",
                        "severity": "Critical",
                        "description": "Patient able to access another patient's medical records",
                        "remediation": "Implement proper authorization checks based on patient identity"
                    })
            except RequestException as e:
                if self.verbose:
                    console.print(f"[yellow]Error testing unauthorized PHI access: {str(e)}[/yellow]")

    def _test_unencrypted_phi_transmission(self) -> None:
        """Test for unencrypted PHI transmission vulnerabilities"""
        if self.verbose:
            console.print("[bold]Testing Unencrypted PHI Transmission[/bold]")
        
        # Check if the API uses HTTPS
        if not self.target_url.startswith("https://") and not self.target_url.startswith("http://localhost"):
            self.vulnerabilities.append({
                "type": "Unencrypted PHI Transmission",
                "endpoint": self.target_url,
                "severity": "Critical",
                "description": "API endpoint does not use HTTPS for PHI transmission",
                "remediation": "Configure proper TLS/SSL for all API endpoints"
            })
        
        # Test for PHI in URL parameters (which could be logged)
        test_endpoints = [
            "/api/patients/search?name=Smith&dob=1980-01-01",
            "/api/appointments?patient_ssn=123-45-6789",
            "/api/medical-records?diagnosis=F41.1"
        ]
        
        for endpoint in test_endpoints:
            url = f"{self.target_url}{endpoint}"
            admin_token = self._simulate_login(self.test_users["admin"])
            
            if admin_token:
                try:
                    headers = {"Authorization": f"Bearer {admin_token}"}
                    response = self.session.get(url, headers=headers, timeout=10)
                    
                    # If successful, this indicates PHI in URLs which is a vulnerability
                    if response.status_code < 400:
                        self.vulnerabilities.append({
                            "type": "PHI in URL Parameters",
                            "endpoint": endpoint,
                            "severity": "High",
                            "description": "PHI exposed in URL parameters which may be logged",
                            "remediation": "Use POST requests with encrypted body for PHI transmission"
                        })
                except RequestException:
                    pass  # Connection error is not a vulnerability in this context

    def _test_audit_logging(self) -> None:
        """Test for HIPAA audit logging compliance"""
        if self.verbose:
            console.print("[bold]Testing Audit Logging Compliance[/bold]")
        
        # This test is simulated since we can't directly check server-side audit logs
        # We test API endpoints that should return audit capabilities
        
        admin_token = self._simulate_login(self.test_users["admin"])
        if admin_token:
            try:
                url = f"{self.target_url}/api/system/audit-log-status"
                headers = {"Authorization": f"Bearer {admin_token}"}
                response = self.session.get(url, headers=headers, timeout=10)
                
                # If audit log endpoint doesn't exist or returns an error
                if response.status_code >= 400:
                    self.vulnerabilities.append({
                        "type": "Missing Audit Logging",
                        "endpoint": "/api/system/audit-log-status",
                        "severity": "High",
                        "description": "Audit logging system does not appear to be properly configured",
                        "remediation": "Implement HIPAA-compliant audit logging for all PHI access"
                    })
            except RequestException:
                # If endpoint doesn't exist at all, that's a vulnerability
                self.vulnerabilities.append({
                    "type": "Missing Audit Logging",
                    "endpoint": "/api/system/audit-log-status",
                    "severity": "High",
                    "description": "Audit logging system endpoint not found",
                    "remediation": "Implement HIPAA-compliant audit logging for all PHI access"
                })

    def _test_error_information_disclosure(self) -> None:
        """Test for sensitive information disclosure in error messages"""
        if self.verbose:
            console.print("[bold]Testing Error Information Disclosure[/bold]")
        
        # Test deliberate errors to see if they reveal sensitive information
        test_cases = [
            {
                "endpoint": "/api/patients/invalid-id",
                "method": "get",
                "description": "Invalid patient ID"
            },
            {
                "endpoint": "/api/appointments",
                "method": "post",
                "data": {"invalid_field": "value"},
                "description": "Invalid appointment data"
            },
            {
                "endpoint": "/api/auth/login",
                "method": "post",
                "data": {"username": "test_user", "password": ""},
                "description": "Invalid login credentials"
            }
        ]
        
        for test in test_cases:
            url = f"{self.target_url}{test['endpoint']}"
            try:
                if test["method"] == "get":
                    response = self.session.get(url, timeout=10)
                else:
                    data = test.get("data", {})
                    response = self.session.post(url, json=data, timeout=10)
                
                # Check for sensitive information in error responses
                sensitive_patterns = [
                    "exception", "traceback", "stack trace", "at line", 
                    "database error", "syntax error", "ORA-", "MySQL", 
                    "postgres", "sqlite", "mongodb", "user_id", "password"
                ]
                
                response_text = response.text.lower()
                found_patterns = [p for p in sensitive_patterns if p in response_text]
                
                if found_patterns:
                    self.vulnerabilities.append({
                        "type": "Error Information Disclosure",
                        "endpoint": test["endpoint"],
                        "severity": "Medium",
                        "description": f"Error response reveals sensitive information: {', '.join(found_patterns)}",
                        "remediation": "Implement sanitized error handling that doesn't reveal implementation details"
                    })
            except RequestException:
                pass  # Connection error is not a vulnerability in this context

    def _test_brute_force_protection(self) -> None:
        """Test for protection against brute force attacks"""
        if self.verbose:
            console.print("[bold]Testing Brute Force Protection[/bold]")
        
        # Attempt multiple rapid login attempts to detect rate limiting
        url = f"{self.target_url}/api/auth/login"
        
        # Track responses to detect rate limiting
        responses = []
        
        # Perform 10 rapid login attempts
        for i in range(10):
            try:
                data = {
                    "username": f"invalid_user_{i}",
                    "password": "invalid_password"
                }
                response = self.session.post(url, json=data, timeout=10)
                responses.append(response.status_code)
                time.sleep(0.1)  # Small delay to avoid overwhelming the server
            except RequestException:
                pass  # Connection error is not a vulnerability in this context
        
        # Check if rate limiting is implemented
        if len(responses) >= 5 and all(r < 429 for r in responses):
            self.vulnerabilities.append({
                "type": "Missing Rate Limiting",
                "endpoint": "/api/auth/login",
                "severity": "Medium",
                "description": "No rate limiting detected on authentication endpoint",
                "remediation": "Implement rate limiting on login and sensitive endpoints"
            })

    def _test_session_management(self) -> None:
        """Test for secure session management"""
        if self.verbose:
            console.print("[bold]Testing Session Management[/bold]")
        
        admin_token = self._simulate_login(self.test_users["admin"])
        if not admin_token:
            return
        
        # Test 1: Check for session timeout
        try:
            # First access should work
            url = f"{self.target_url}/api/system/status"
            headers = {"Authorization": f"Bearer {admin_token}"}
            response = self.session.get(url, headers=headers, timeout=10)
            
            # JWT tokens should be short-lived for HIPAA compliance
            # Simulate a check after token should have expired (simplified test)
            self._simulate_token_expiry_check(admin_token)
            
        except RequestException as e:
            if self.verbose:
                console.print(f"[yellow]Error testing session management: {str(e)}[/yellow]")

    def _simulate_login(self, credentials: Dict[str, str]) -> Optional[str]:
        """Simulate a login to obtain an authentication token"""
        try:
            url = f"{self.target_url}/api/auth/login"
            response = self.session.post(url, json=credentials, timeout=10)
            
            # Simulate token extraction from response
            if response.status_code < 400:
                # Try to extract token from response
                try:
                    data = response.json()
                    return data.get("token", "simulated_token_for_testing")
                except ValueError:
                    return "simulated_token_for_testing"
            return None
        except RequestException:
            return None

    def _simulate_jwt_attack(self) -> None:
        """Simulate JWT token tampering attacks"""
        # This is a simplified simulation since we can't perform actual JWT attacks in this test
        # We just check if JWT validation is potentially vulnerable
        
        # Check endpoints for JWT validation issues (simplistic approach)
        admin_token = self._simulate_login(self.test_users["admin"])
        if not admin_token:
            return
        
        tampered_tokens = [
            # Simulate invalid signature
            f"{admin_token.split('.')[0]}.{admin_token.split('.')[1]}.invalid",
            # Simulate none algorithm attack
            f"eyJhbGciOiJub25lIiwidHlwIjoiSldUIn0.{admin_token.split('.')[1]}.",
        ]
        
        test_endpoint = f"{self.target_url}/api/patients"
        
        for token in tampered_tokens:
            try:
                headers = {"Authorization": f"Bearer {token}"}
                response = self.session.get(test_endpoint, headers=headers, timeout=10)
                
                # If tampered token is accepted, it's a critical vulnerability
                if response.status_code < 400:
                    self.vulnerabilities.append({
                        "type": "JWT Validation Vulnerability",
                        "endpoint": test_endpoint,
                        "severity": "Critical",
                        "description": "Tampered JWT token was accepted by the API",
                        "remediation": "Implement proper JWT validation with signature verification"
                    })
                    break
            except RequestException:
                pass  # Connection error is not a vulnerability in this context

    def _simulate_token_expiry_check(self, token: str) -> None:
        """Simulate checking if token expiry is properly enforced"""
        # In a real test, we would wait for token expiry
        # Here we're just checking if expiry headers are present in the token
        
        # Base64 decode the payload part of the token to check for expiry
        # This is a simplistic approach for demonstration
        try:
            import base64
            import json
            
            # Get the payload part (second segment)
            payload_part = token.split('.')[1]
            
            # Add padding if needed
            padding = len(payload_part) % 4
            if padding:
                payload_part += '=' * (4 - padding)
            
            # Decode
            payload_bytes = base64.b64decode(payload_part)
            payload = json.loads(payload_bytes.decode('utf-8'))
            
            # Check for expiry claim
            if 'exp' not in payload:
                self.vulnerabilities.append({
                    "type": "Missing Token Expiry",
                    "endpoint": "JWT Authentication",
                    "severity": "Medium",
                    "description": "JWT tokens do not include expiration time",
                    "remediation": "Configure JWT tokens with appropriate short expiry times"
                })
        except Exception:
            # If we can't decode, we'll assume token includes expiry for this test
            pass

    def _prepare_results(self) -> Dict:
        """Prepare the full test results"""
        severity_counts = {
            "Critical": 0,
            "High": 0,
            "Medium": 0,
            "Low": 0
        }
        
        for vuln in self.vulnerabilities:
            severity = vuln.get("severity", "Low")
            if severity in severity_counts:
                severity_counts[severity] += 1
        
        # Calculate compliance score (simplified)
        max_score = 100
        deductions = {
            "Critical": 25,
            "High": 10,
            "Medium": 5,
            "Low": 2
        }
        
        score = max_score
        for severity, count in severity_counts.items():
            score -= count * deductions[severity]
        
        score = max(0, score)  # Ensure score is not negative
        
        compliance_status = "Compliant"
        if score < 60 or severity_counts["Critical"] > 0:
            compliance_status = "Non-Compliant"
        elif score < 80:
            compliance_status = "Partially Compliant"
        
        return {
            "test_id": self.test_id,
            "timestamp": self.test_timestamp,
            "target_url": self.target_url,
            "summary": {
                "compliance_score": score,
                "compliance_status": compliance_status,
                "critical_findings": severity_counts["Critical"],
                "high_findings": severity_counts["High"],
                "medium_findings": severity_counts["Medium"],
                "low_findings": severity_counts["Low"],
                "total_vulnerabilities": len(self.vulnerabilities)
            },
            "vulnerabilities": self.vulnerabilities
        }

    def _save_results(self, results: Dict) -> None:
        """Save test results to files"""
        # Save as JSON
        json_path = os.path.join(self.output_dir, "pentest_results.json")
        with open(json_path, 'w') as f:
            json.dump(results, f, indent=2)
        
        # Save as markdown report
        md_path = os.path.join(self.output_dir, "pentest_report.md")
        with open(md_path, 'w') as f:
            f.write(f"# HIPAA Penetration Test Report\n\n")
            f.write(f"**Test ID:** {results['test_id']}\n")
            f.write(f"**Timestamp:** {results['timestamp']}\n")
            f.write(f"**Target URL:** {results['target_url']}\n\n")
            
            f.write("## Summary\n\n")
            f.write(f"**Compliance Score:** {results['summary']['compliance_score']}/100\n")
            f.write(f"**Compliance Status:** {results['summary']['compliance_status']}\n\n")
            
            f.write("### Findings\n\n")
            f.write(f"- Critical: {results['summary']['critical_findings']}\n")
            f.write(f"- High: {results['summary']['high_findings']}\n")
            f.write(f"- Medium: {results['summary']['medium_findings']}\n")
            f.write(f"- Low: {results['summary']['low_findings']}\n")
            f.write(f"- Total Vulnerabilities: {results['summary']['total_vulnerabilities']}\n\n")
            
            f.write("## Vulnerabilities\n\n")
            for i, vuln in enumerate(results['vulnerabilities'], 1):
                f.write(f"### {i}. {vuln['type']}\n\n")
                f.write(f"**Severity:** {vuln['severity']}\n")
                f.write(f"**Endpoint:** {vuln['endpoint']}\n")
                f.write(f"**Description:** {vuln['description']}\n")
                f.write(f"**Remediation:** {vuln['remediation']}\n\n")
        
        if self.verbose:
            console.print(f"[green]Results saved to {json_path} and {md_path}[/green]")

    def _display_summary(self, results: Dict) -> None:
        """Display a summary of the test results"""
        table = Table(title="HIPAA Penetration Test Results")
        
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="green")
        
        table.add_row("Target URL", results["target_url"])
        table.add_row("Compliance Score", f"{results['summary']['compliance_score']}/100")
        table.add_row("Compliance Status", results['summary']['compliance_status'])
        table.add_row("Critical Findings", str(results['summary']['critical_findings']))
        table.add_row("High Findings", str(results['summary']['high_findings']))
        table.add_row("Medium Findings", str(results['summary']['medium_findings']))
        table.add_row("Low Findings", str(results['summary']['low_findings']))
        table.add_row("Total Vulnerabilities", str(results['summary']['total_vulnerabilities']))
        
        console.print(table)
        
        if results['vulnerabilities']:
            console.print("\n[bold red]Critical & High Vulnerabilities:[/bold red]")
            for vuln in results['vulnerabilities']:
                if vuln['severity'] in ['Critical', 'High']:
                    console.print(f"[red]{vuln['severity']}[/red]: {vuln['type']} - {vuln['description']}")


def parse_args() -> argparse.Namespace:
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description="HIPAA Penetration Testing Suite")
    parser.add_argument("url", help="Target URL for testing")
    parser.add_argument("--verbose", "-v", action="store_true", help="Enable verbose output")
    parser.add_argument("--output-dir", "-o", default="security-reports", help="Directory to save test results")
    return parser.parse_args()


def main() -> None:
    """Main function"""
    args = parse_args()
    
    try:
        pentest = HIPAAPentestSuite(args.url, args.output_dir, args.verbose)
        pentest.run_all_tests()
    except KeyboardInterrupt:
        console.print("\n[yellow]Test interrupted by user[/yellow]")
        sys.exit(1)
    except Exception as e:
        console.print(f"\n[bold red]Error running tests: {str(e)}[/bold red]")
        sys.exit(1)


if __name__ == "__main__":
    main()